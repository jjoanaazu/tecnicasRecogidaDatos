{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entregable 1\n",
    "### Técnicas de Recogida de Datos - Joaquín Joana Azuara - Máster Big Data Science, Universidad de Navarra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkedIn: https://www.linkedin.com/in/joaqu%C3%ADn-joana-azuara-92911a21b/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice ##\n",
    "\n",
    "1. ¿Qué es el web scraping?\n",
    "\n",
    "2. BeautifulSoup\n",
    "\n",
    "3. Selenium\n",
    "\n",
    "4. Funciones Implementadas\n",
    "\n",
    "5. Problemas Encontrados en la realización de la práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es el web scraping?\n",
    "Web scraping es una técnica utilizada mediante programas de software que permite extraer información de sitios web. Usualmente, estos programas simulan la navegación de un humano en la World Wide Web.\n",
    "\n",
    "Existen distintos niveles de automatización que podemos aplicar a la hora de hacer Web Scraping. En este caso, se utilizarán librerías disponibles en internet para personalizar soluciones de Web Scraping. Estas librerías permitirán reconocer automáticamente la estructura de las páginas web que queremos analizar pudiendo seleccionar los campos que son de interés dentro del documento.\n",
    "\n",
    "Las librerías utilizadas en este proyecto han sido:\n",
    "- Selenium\n",
    "- BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium\n",
    "Selenium es una librería que permite automatizar la navegación de páginas web mediante navegadores. Está principalmente enfocado al testeo de aplicaciones web aunque también permite desarrollar flujos de trabajo como es el caso de las técnicas de scraping.\n",
    "\n",
    "### Requisitos para utilizar Selenium\n",
    "- NAVEGADOR WEB\n",
    "Selenium necesita un navegador web instalado en el sistema para poder funcionar. Dentro de las opciones disponibles están Chrome, Firefox, Edge, Internet Explorer y Safari. **En el caso de este proyecto se va a utilizar Chrome**.\n",
    "\n",
    "- DRIVER\n",
    "Además de esto, también es necesario disponer un **webdriver** que permita manejar el navegador (a modo de marioneta). Cada navegador tiene asociado un tipo de «driver». **El único propósito del ChromeDriver es lanzar e interactuar con Google Chrome**. Sin usar ChromeDriver, no es posible ejecutar pruebas de Selenium en el navegador Chrome. Es por ello que es uno de los prerrequisitos vitales a la hora de hacer scraping mediante Chrome\n",
    "\n",
    "- CONFIGURACIÓN DEL DRIVER\n",
    "El driver es el manejador de las peticiones del usuario. Se trata del objeto fundamental en Selenium que nos permitirá interactuar con el navegador y los sitios web.\n",
    "\n",
    "- INICIALIZACIÓN DEL DRIVER\n",
    "Para inicializar el «driver», en su versión más simple, usaremos el siguiente código:\n",
    "> path_chromedriver = \"C:/........./chromedriver.exe\"\\\n",
    "> s = Service(path_chromedriver)\\\n",
    "> chrome_options = webdriver.ChromeOptions()\\\n",
    "> chrome_options.add_argument(\"--incognito\")\\\n",
    "> browser = webdriver.Chrome(service=s, options=chrome_options)\n",
    "\n",
    "### Consideraciones generales al utilizar esta librería\n",
    "Al realizar cualquier solicitud de información mediante selenium, se procederá de la siguiente forma:\n",
    "1. Se pasará como parámetro la URL del sitio web deseado.\n",
    "> browser = webdriver.Chrome(service=s, options=chrome_options)\\\n",
    "> wait = WebDriverWait(browser, 10)\\\n",
    "> browser.get(\"https://stackoverflow.com/\")\n",
    "2. Se implementará un bloque Try/Except para manejar una situación de **tiempo de espera** o **elemento no localizado** en caso de que ocurra.\n",
    "> try:\n",
    "- wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR, \"etiqueta[atributo=[xxx]\")))\n",
    "- elemento = browser.find_element(By.CSS_SELECTOR, \"etiqueta[atributo=[xxx]\")\n",
    "- elemento.click()\n",
    "> except (NoSuchElementException, TimeoutException) as ex:\n",
    "- browser.quit()\n",
    "3. Los **tiempos de espera** desde el momento de carga de una página web y el inicio de busqueda de la información dentro de ella se ha realizado (casí siempre), mediante lo que Selenium denomina **Espera explícita**, es decir, ya que el tiempo de espera necesario en cargar una página web es variable, se han definido ciertas condiciones hasta el inicio de la busqueda de la información. Solo después de que se cumpla esta condición, se inicia la búsqueda de esta, evitándose así que se produzca una excepción de tipo \"elemento no encontrado\":\n",
    "- wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR, \"etiqueta[atributo=[xxx]\")))\n",
    "- elemento = browser.find_element(By.CSS_SELECTOR, \"etiqueta[atributo=[xxx]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "Beautiful Soup es una librería sencilla de utilizar. La librería **BeautifulSoup** es ampliamente utilizada en técnicas de**scraping** permitiendo **parsear** principalmente código HTML.\n",
    "\n",
    "A partir de aquí lo único que hay que hacer es ir buscando los elementos que deseamos... \n",
    "\n",
    "Para empezar a trabajar con BeautifulSoup es necesario construir un objeto de tipo BeautifulSoup que reciba el documento que queremos parsear:\n",
    "\n",
    "> from bs4 import BeautifulSoup\\\n",
    "> url = '''\\\n",
    "> soup = BeautifulSoup(url, features='html.parser')\n",
    "\n",
    "A partir de aquí se pueden realizar muchas funciones relacionadas con el escrapeo de código HTML:\n",
    "- Localizar elementos\n",
    "- Acceder al contenido de un elemento\n",
    "- Navegar por el DOM del documento\n",
    "- Información adicional en: <https://aprendepython.es/pypi/scraping/beautifulsoup/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El primer paso para el proyecto ha sido importar el conjunto de las librerías necesarias. No solo las utilizadas para realizar el scraping, si no también las requeridas para el manejo de datos, tiempo, excepciones, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Excepciones controladas en este programa.\n",
    "from selenium.common.exceptions import (\n",
    "    ElementNotSelectableException, ElementNotVisibleException, NoSuchElementException,\n",
    "    TimeoutException, WebDriverException, WebDriverException)\n",
    "\n",
    "# Librerías varias\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Librerías para manejo de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones implementadas:\n",
    "Se han utilizado funciones a la hora de implementar la funcionalidad requerida para el programa.\n",
    "- def login()\n",
    "- def accept_cookies_stackoverflow()\n",
    "- def acceso_cuenta()\n",
    "- def get_SOS_help(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Aspectos generales de la implementación: Todas las funciones están protegidas mediante bloque **try - except**, de tal forma que cualquier excepción/error que se produzca durante la ejecución de su código pueda ser capturado para darle el tratamiento que se consideré más adecuado en cada caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función login()\n",
    "\n",
    "Función que permite seleccionar y realizar click en el botón superior derecho de la página de inicio de https://stackoverflow.com  que da acceso a la ventana de log in.\n",
    "\n",
    "Las únicas excepciones/errores que pueden ocurrir durante la ejecución de las líneas de código que hay dentro del bloque try son:\n",
    "> NoSuchElementException\\\n",
    "> TimeoutException\n",
    "\n",
    "En caso de que se produzca alguna excepción distinta de estas, el programa cerrará (\"morirá\") cerrando el navegador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login():\n",
    "    try:\n",
    "        wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR, \"nav[class='h100 ml-auto overflow-x-auto pr12']\")))\n",
    "        login_button = browser.find_element(By.CSS_SELECTOR, \"a[data-gps-track='login.click']\")\n",
    "        login_button.click()\n",
    "    except (NoSuchElementException, TimeoutException) as ex:\n",
    "        print(\"Excepción al hacer login stack overflow: \", type(ex))\n",
    "        browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función accept_cookies_stackoverflow()\n",
    "\n",
    "Esta segunda función permite saltar la ventana emergente de cookies que muestra el navegador al intentar acceder a la página web. La implementación realizada es similar a la de login()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_cookies_stackoverflow():\n",
    "    try:\n",
    "        wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR,\n",
    "                                                     \"button[class='flex--item s-btn s-btn__primary js-accept-cookies js-consent-banner-hide']\")))\n",
    "        cookies_button = browser.find_element(By.CSS_SELECTOR,\n",
    "                                              \"button[class='flex--item s-btn s-btn__primary js-accept-cookies js-consent-banner-hide']\")\n",
    "        cookies_button.click()\n",
    "    except (NoSuchElementException, TimeoutException, ElementNotVisibleException) as ex:\n",
    "        print(\"Excepción al aceptar cookies de stack overflow: \", type(ex))\n",
    "        browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función acceso_cuenta()\n",
    "\n",
    "Esta función sirve para que una vez después de haber pasado por login y haber aceptado las cookis, nos lleve a esta parte de la web (https://stackoverflow.com/users/login?ssrc=head&returnurl=https%3a%2f%2fstackoverflow.com%2f) donde se solicita que se introduzca el email o usuario y la contraseña o password. Se pide esto para poder acceder a nuestra cuenta de Sack overflow, la cual se habrá creado antes de ejecutar este programa.\n",
    "\n",
    "Esta función requiere que se establezcan el usuario y la password que se dispone en Stack overflow (**en caso contrario, el programa falla**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceso_cuenta():\n",
    "    try:\n",
    "        wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR, \"input[id='email']\")))\n",
    "        username = browser.find_element(By.CSS_SELECTOR, \"input[id='email']\")\n",
    "        wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR, \"input[id='password']\")))\n",
    "        password = browser.find_element(By.CSS_SELECTOR, \"input[id='password']\")\n",
    "        username.clear()\n",
    "        password.clear()\n",
    "        username.send_keys(usuario)\n",
    "        password.send_keys(clave)\n",
    "        wait.until(ec.visibility_of_element_located((By.CSS_SELECTOR, \"button[id='submit-button']\")))\n",
    "        login_button = browser.find_element(By.CSS_SELECTOR, \"button[id='submit-button']\")\n",
    "        login_button.click()\n",
    "    except (NoSuchElementException, TimeoutException, ElementNotVisibleException) as ex:\n",
    "        print(\"Excepción al intentar acceder a mi cuenta de stack overflow: \", type(ex))\n",
    "        browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función get_SOS_help(command)\n",
    "\n",
    "Por último se implementa la función \"clave\" de este programa.\n",
    "\n",
    "### Parámetros requeridos: \"command\"\n",
    "La buit-in función de Python **exec()** permite ejecutar código Python arbitrario desde una cadena o entrada de código compilado. La función exec() puede ser útil cuando se necesita ejecutar código Python generado dinámicamente.\n",
    "\n",
    "La función **exec()** toma un fragmento de código y lo ejecuta como lo haría su intérprete de Python. exec() puede ejecutar secuencias de instrucciones, así como importaciones, llamadas y definiciones de funciones, así como instancias de clases, y más. Esencialmente, exec() puede ejecutar un programa Python completo con todas las funciones.\n",
    "\n",
    "En caso de que se produzca una excepción al ejecutar el programa \"command\", se entrará en el except y mediante el uso de la librería selenium se realizará la busqueda de la solución más votada a ese problema en la web de Stack overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SOS_help(command):\n",
    "    try:\n",
    "        exec(command)\n",
    "    except Exception as e:\n",
    "        time.sleep(2)\n",
    "        box_error = browser.find_element(By.CSS_SELECTOR, \"input[role='combobox']\")\n",
    "        box_error.send_keys(str(e))\n",
    "        box_error.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "        more_button = browser.find_element(By.CSS_SELECTOR,\n",
    "                                 \"button[class='s-btn s-btn__muted s-btn__outlined s-btn__dropdown blr0 brr-sm js-dropdown-toggle']\")\n",
    "        more_button.click()\n",
    "        time.sleep(2)\n",
    "        score_button = browser.find_element(By.CSS_SELECTOR, \"a[title='Highest scored search results']\")\n",
    "        score_button.click()\n",
    "\n",
    "        time.sleep(3)\n",
    "        lista_soluciones = browser.find_elements(By.CSS_SELECTOR, \"a[href]\")\n",
    "        solucion_seleccionada = lista_soluciones[55]\n",
    "        solucion_seleccionada.send_keys(Keys.RETURN)\n",
    "\n",
    "        #obtener\n",
    "        lista_html = browser.find_elements(By.CSS_SELECTOR, \"div[class='s-prose js-post-body']\")\n",
    "        soup = BeautifulSoup(str(lista_html[1].text), 'html.parser')\n",
    "        print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El código siguiente pone en ejecución el programa haciendo uso de todas las funciones anteriormente explicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicio del programa\n",
    "# Inicialización variables del programa\n",
    "path_chromedriver = \"C:/Users/XXXXXXXXXXXXX/chromedriver.exe\"\n",
    "usuario = \"XXXXX@gmail.com\"\n",
    "clave = \"XXXXXX\"\n",
    "\n",
    "# Crear una instancia del navegador en modo incognito\n",
    "s = Service(path_chromedriver)\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "browser = webdriver.Chrome(service=s, options=chrome_options)\n",
    "wait = WebDriverWait(browser, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abro Stack Overflow\n",
    "browser.get(\"https://stackoverflow.com/\")\n",
    "login()\n",
    "accept_cookies_stackoverflow()\n",
    "actual_site = acceso_cuenta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python working a bit differently to JavaScript for example, the value you are concatenating needs to be same type, both int or str...\n",
      "So for example the code below throw an error:\n",
      "print( \"Alireza\" + 1980)\n",
      "like this:\n",
      "Traceback (most recent call last):\n",
      "  File \"<pyshell#12>\", line 1, in <module>\n",
      "    print( \"Alireza\" + 1980)\n",
      "TypeError: can only concatenate str (not \"int\") to str\n",
      "To solve the issue, just add str to your number or value like:\n",
      "print( \"Alireza\" + str(1980))\n",
      "And the result as:\n",
      "Alireza1980</module></pyshell#12>\n"
     ]
    }
   ],
   "source": [
    "mycode='''\n",
    "product = {\"item\": \"iPhone\",\"price\": 1599,\"qty_available\": 40}\n",
    "print(\"We have total \" + product[\"qty_available\"] + \" quantities of Product \" + product[\"item\"])\n",
    "'''\n",
    "\n",
    "get_SOS_help(mycode)\n",
    "\n",
    "time.sleep(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas Econtrados en la realización de la práctica\n",
    "Siempre que empiezo a trabajar en un nuevo proyecto (en este caso scraping de páginas web) surge la duda de cuál es la técnica más apropiada para afrontar el trabajo. En este caso, el profesor nos ha dado ideas bastante precisas sobre las técnicas y librerías más apropiadas para realizar la práctica.\n",
    "\n",
    "No obstante, saber las librerías más adecuadas para realizar el trabajo no resuelve el problema. Es necesario conocer las característivas de esa librería antes de poder utilizarla.\n",
    "\n",
    "## Problemas encontrados programando con la librería Selenium\n",
    "Selenium permite probar y registrar las interacciones con una aplicación web y luego repetirlas las veces que se desee, de forma completamente automática. El componente de Selenium que he utilizado para realizar el scraping ha sido **Selenium WebDriver** que es una API simple que permite simular las interacciones del usuario con cualquier navegador, ya sea Firefox, Chrome, Edge, Safari o Internet Explorer. Desde 2018, la API es un estándar W3C oficial.\n",
    "\n",
    "Me costó un tiempo entender la arquitectura de una aplicación con Selenium hasta que me di cuenta de que era necesario descargar e instalar el controlador del navegador al que quiero conectar Selenium (decidí utilizar Chrome por lo que tuve que descargarme el driver adecuado: 'chromedriver.exe')\n",
    "\n",
    "A partir de ahí, con los ejemplos que encontré en internet, pude automatizar las interacciones con el navegador Chrome mediante clases y funciones de Selenium, en concreto observé que la secuencia estándar consiste en:\n",
    "- Crear una instancia de Chrome que posteriormente controlaré mediante comandos de Selenium\n",
    "- Cargar la página de inicio de 'Stackoverflow' que sirve de base para las interacciones automatizadas (posteriormente iré navegando por distintas páginas)\n",
    "- Buscar los elementos con los que quiera interactuar en cada página\n",
    "\n",
    "> Este último punto me creó grandes problemas y me supuso mucho tiempo. Fue complicado descubrir el motivo de los errores que se producián en el programa a la hora de buscar la información que debía estar en el archivo html con el que estaba trabajando.\n",
    "\n",
    "Cuando una página es cargada por el navegador, los elementos con los que queremos interactuar pueden cargarse a intervalos de tiempo diferentes. Esto no sólo provoca que sea difícil identificar el elemento, sino también, en el caso de que el elemento no esté situado, se producirá una excepción de tipo **'NoSuchElementException'**, **ElementNotVisibleException** y **'TimeoutException'** si la página no se carga dentro de un tiempo específico. Usando las esperas, pude resolver este problema.\n",
    "\n",
    "En Selenium hay dos tipos de esperas.\n",
    "- Implicit Wait: se utiliza para establecer el tiempo de espera predeterminado en todo el programa.\n",
    "- Explicit Wait: se utiliza para establecer el tiempo de espera para solo una instancia en particular.\n",
    "\n",
    "En resumen, Implicit Wait obliga a que el programa espere un tiempo sin que deba cumplirse condición alguna. Explicit Wait supondrá que el programa realice un tiempo de espera dependiendo de la condición que se establezca.\n",
    "\n",
    "He utilizado 'Implicit Wait' para que el WebDriver espere un tiempo antes de que lance una excepción de tipo **'NoSuchElementException'**. Configurado el tiempo, el WebDriver esperará ese tiempo antes de lanzar una excepción.\n",
    "\n",
    "He utilizado 'Explicit Wait' para que el WebDriver espere ciertas condiciones (Expected Conditions) o el tiempo máximo excedido antes de lanzar una excepción **'ElementNotVisibleException'**.\n",
    "\n",
    "He podido comprobar que la librería Selenium WebDriver: no es muy útil para hacer scraping en algunas circunstancias:\n",
    "- **Captchas**: que se desarrollaron especialmente para proteger de los bots y el spam, por lo que no están disponibles para procesos de automatización con Selenium.\n",
    "- **Códigos de respuesta HTTP**: Selenium tiene problemas para tratar con códigos de estado HTTP. (Parece que se pueden compensar estas desventajas usando un proxy adicional si es necesario).\n",
    "- **Iniciar sesión en los servicios de terceros**: tanto si se trata de una plataforma de redes sociales, como un servicio en la nube o una cuenta de correo electrónico, no es recomendable iniciar sesión en los servicios de terceros a través de una sesión de Selenium. Dos son los motivos:\n",
    "-    Los proveedores de esos servicios proporcionan sus propias API con fines de prueba\n",
    "-    Las pruebas con el marco de trabajo en esos casos pueden ser muy laboriosas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c812eb984687e98b7686c463c3fae2045e58b2a2b4e065b3dcebe3cb7d51662e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
